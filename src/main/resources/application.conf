akka {
  # Loggers to register at boot time (akka.event.Logging$DefaultLogger logs
  # to STDOUT)
  loggers = ["akka.event.slf4j.Slf4jLogger"]

  # Log level used by the configured loggers (see "loggers") as soon
  # as they have been started; before that, see "stdout-loglevel"
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  loglevel = "DEBUG"

  # Log level for the very basic logger activated during ActorSystem startup.
  # This logger prints the log messages to stdout (System.out).
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  stdout-loglevel = "DEBUG"

  # Filter of log events that is used by the LoggingAdapter before
  # publishing log events to the eventStream.
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  event-handlers = ["akka.event.slf4j.Slf4jLogger"]

  log-config-on-start = "off"

  actor {
    provider = "akka.remote.RemoteActorRefProvider"
  }

  //    remote {
  enabled-transports = ["akka.remote.netty.tcp", "akka.remote.netty.NettyRemoteTransport"]

  remote {
    maximum-payload-bytes = 30000000 bytes
    netty.tcp {
      message-frame-size = 30000000b
      send-buffer-size = 30000000b
      receive-buffer-size = 30000000b
      maximum-frame-size = 30000000b
    }
  }
}

arcite {
  home_name = "home"
  snapshot_name = "experiments_snapshot.json"
  file_service {
    snapshot_name = "file_service.json"
  }
}

api.specification = """arcite API:
          |
          |
          |GET  /experiments ==>  return all experiments summary info or a few hundred if there are too many
          |
          |
          |GET  /experiments?search=searchString&maxHits=number ==>  searching for the given string in the experiments and returning a maximum of maxHits results
          |
          |
          |POST /experiments {"search" : "search string", "maxHits": 10} ==>   return all experiments for the given search string, same as previous but with post
          |
          |
          |GET  /experiment/{uid} ==>  return one experiment with every information regarding its design
          |
          |
          |DELETE  /experiment/{uid} ==>  delete the experiment
          |
          |
          |GET  /experiment/{uid}/transforms ==>  returns all the transforms for this experiment
          |
          |
          |POST  /experiment/{uid}/file_upload/meta ==>  upload a file to the meta information section (e.g. curl --form "fileupload=@file" http://server:port/experiment/{uid}/file_upload/meta
          |
          |
          |POST  /experiment/{uid}/file_upload/raw ==>  upload a file to the raw data section (e.g. curl --form "fileupload=@file" http://server:port/experiment/{uid}/file_upload/raw
          |
          |
          |POST  /experiment/{uid}/properties ==>  add properties to the experiment {"property_name" : "property_value"}
          |
          |
          |GET  /experiment/{uid}/files/raw ==>  returns list of raw files
          |
          |
          |GET  /experiment/{uid}/files/meta ==>  returns list of meta files
          |
          |
          |POST /experiment {"experiment" : "...."}  ==>  add a new experiment
          |
          |
          |POST /experiment/clone {"experiment" : "....", "organization": "new organization path, if not specified, will use the original", "name": "new name"}  ==>  clone an experiment
          |
          |
          |POST /design {"experiment": "uid", "design": {"description" : "desc", "sampleConditions" : [[{"name": "AA1", "description": "AA1", "category": "sampleID"}, {"name": "ACT-1234", "description": "ACT-1234", "category": "compound"}]..]}} ==>  add design to experiment
          |
          |
          |POST /raw_data/files {"experiment": "uid", "filesAndTarget" : ["rawfiles list"], "transferFiles": boolean } ==>  defines raw files for a experiment, files and target is a map, one original file to a target name for the file. If target name is omited, arcite will take the current file name.
          |
          |
          |POST /raw_data/folder {"experiment": "uid", "folder" : "folder", "regex": "regex", "withSubfolder": boolean, "transferFiles": boolean} ==>  defines raw data folder with regex to pick up files for a experiment
          |
          |
          |GET  /transform_definitions ==>   returns all possible transform definitions
          |
          |
          |GET  /transform_definitions?search=search_string ==>  returns all transform definitions based on search criteria
          |
          |
          |GET  /transform_definition/{uid} ==>   one specific transform
          |
          |
          |POST /run_transform/{"experiment": "uid", "transformDefinition": "uid", "parameters": JSValue} ==>  run the specified transform on the given experiment with the given json parameters as parameter object
          |
          |
          |POST /run_transform/on_transform/{"experiment": "uid", "transformDefinition": "uid", "transformOrigin" :"uid", "parameters": JSValue} ==>  run the specified transform on the given experiment starting from another transform, the given json parameter can be added
          |
          |
          |POST /run_transform/on_raw_data/{"experiment": "uid", "transformDefinition": "uid", "transformOrigin" :"uid", "parameters": JSValue} ==>  run the specified transform on the given experiment starting with the default raw data (usually the first transform), the given json parameter can be added
          |
          |
          |POST /run_transform/on_transform_with_exclusions/{"experiment": "uid", "transformDefinition": "uid", "transformOrigin" :"uid",  "excludes": [], "excludesRegex": [], "parameters": JSValue} ==>  run the specified transform on the given experiment starting from another transform, the given json parameter can be added
          |
          |
          |POST /run_transform/on_raw_data_with_exclusions/{"experiment": "uid", "transformDefinition": "uid", "transformOrigin" :"uid", "excludes": [], "excludesRegex": [], parameters": JSValue} ==>  run the specified transform on the given experiment starting with the default raw data (usually the first transform), the given json parameter can be added
          |
          |
          |GET /job_status/{uid} ==>  information about the job with the given uid
          |
          |
          |GET /all_jobs_status ==>  information about all current jobs (running, completed, in progress, ...)
          |"""


transform_worker {
  akka {
    remote {
      maximum-payload-bytes = 30000000 bytes
      netty.tcp {
        message-frame-size = 30000000b
        send-buffer-size = 30000000b
        receive-buffer-size = 30000000b
        maximum-frame-size = 30000000b
      }
    }
  }
}

transform_cluster {
  akka {
    remote {
      maximum-payload-bytes = 30000000 bytes
      netty.tcp {
        message-frame-size = 30000000b
        send-buffer-size = 30000000b
        receive-buffer-size = 30000000b
        maximum-frame-size = 30000000b
      }
    }
  }
}

experiments-manager {
  akka {
    remote {
      maximum-payload-bytes = 30000000 bytes
      netty.tcp {
        message-frame-size = 30000000b
        send-buffer-size = 30000000b
        receive-buffer-size = 30000000b
        maximum-frame-size = 30000000b
      }
    }
  }
}
